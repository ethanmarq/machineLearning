{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec65cf91-a973-4086-a207-23999501f156",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px;background-color:tomato;\" >Dataset</p>\n",
    "https://www.kaggle.com/datasets/gonzalorecioc/color-polygon-images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0eb6c2-ffde-49f2-8e6b-160b2fb8a676",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px;\"><strong>Importing Libraries</strong></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29bc9eb8-6fca-43e6-ad27-160b2e53faf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import skimage.color\n",
    "import skimage.data\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import img_to_array, load_img\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3129b65-2eb3-4c9a-9c31-764bf00bab32",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px;\"><strong>Importing Data</strong></p>\n",
    "<p style=\"font-size:15px;\">Creates train dataset from 10,000 images</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b29ec99-7751-4d07-ae03-4f427667deb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10001 files belonging to 1 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-23 09:41:08.176032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4077 MB memory:  -> device: 0, name: Tesla K20m, pci bus id: 0000:24:00.0, compute capability: 3.5\n"
     ]
    }
   ],
   "source": [
    "#Imports Data\n",
    "train_ds = keras.utils.image_dataset_from_directory(\n",
    "    directory='archive/images/content/images',\n",
    "    labels=None,\n",
    "    batch_size=32,\n",
    "    image_size=(128, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1722cf31-58de-4c7f-9e99-3a997c9d0222",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px;\"><strong>Prints Pixels in Number Form</strong></p>\n",
    "<p style=\"font-size:15px;\">no bueno</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd07fc04-043f-4ead-8a38-957d29f32eed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#prints pixels for images\\nfor element in train_ds:\\n  print(element)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#prints pixels for images\n",
    "for element in train_ds:\n",
    "  print(element)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72da7908-5c33-454c-bfc0-41ec024d20ce",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px;\"><strong>Adjusts Collums</strong></p>\n",
    "<p style=\"font-size:15px;\">Drops majority of collums to make dataset easier to read, and prints dataset</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cf962b6-815b-4772-ae7f-318cb3c506c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>sides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70aaa621-1345-4541-a954-ee9856daaf18.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ea0d8d14-596a-4365-b007-6325fc96e0f4.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48c1fc5a-8b6b-4555-bb6a-a7d42a5cedc2.png</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ad721906-604c-4682-ae5d-15539ef1dbc7.png</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510dd5ea-fb92-432e-91cc-ed4654a03ebd.png</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   filename  sides\n",
       "0  70aaa621-1345-4541-a954-ee9856daaf18.png      4\n",
       "1  ea0d8d14-596a-4365-b007-6325fc96e0f4.png      3\n",
       "2  48c1fc5a-8b6b-4555-bb6a-a7d42a5cedc2.png      4\n",
       "3  ad721906-604c-4682-ae5d-15539ef1dbc7.png      3\n",
       "4  510dd5ea-fb92-432e-91cc-ed4654a03ebd.png      6"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Cleans up Data\n",
    "df = pd.read_csv('archive/targets.csv')\n",
    "df = df.drop(columns=['Unnamed: 0', 'bg_color', 'fg_color', 'bound_circle_x', 'bound_circle_y', 'bound_circle_r', 'rotation'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc80919-3b5e-4aca-84b0-49af5bdc058e",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px;\"><strong>Adding Collums</strong></p>\n",
    "<p style=\"font-size:15px;\">Creates shape and copies sides data to it</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3da3b1ce-04d8-496b-8b0e-fd1eaa81ebf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>sides</th>\n",
       "      <th>shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70aaa621-1345-4541-a954-ee9856daaf18.png</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ea0d8d14-596a-4365-b007-6325fc96e0f4.png</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48c1fc5a-8b6b-4555-bb6a-a7d42a5cedc2.png</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ad721906-604c-4682-ae5d-15539ef1dbc7.png</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510dd5ea-fb92-432e-91cc-ed4654a03ebd.png</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   filename  sides  shape\n",
       "0  70aaa621-1345-4541-a954-ee9856daaf18.png      4      4\n",
       "1  ea0d8d14-596a-4365-b007-6325fc96e0f4.png      3      3\n",
       "2  48c1fc5a-8b6b-4555-bb6a-a7d42a5cedc2.png      4      4\n",
       "3  ad721906-604c-4682-ae5d-15539ef1dbc7.png      3      3\n",
       "4  510dd5ea-fb92-432e-91cc-ed4654a03ebd.png      6      6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creates a new collum for shape\n",
    "data = []\n",
    "for i in range(len(df)):\n",
    "  data.append(df.iloc[i].sides)\n",
    "if data == 3:\n",
    "    data = 'traingle'\n",
    "df['shape'] = data\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccce0c7c-999b-4402-b5ed-41758801164d",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px;\"><strong>Creates Dictionaries</strong></p>\n",
    "<p style=\"font-size:15px;\">First dictionary to make code readable for humans</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ab6e6d6-813d-402c-b060-bc05c9bb767d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 'traingle', 4: 'square', 5: 'pentagon', 6: 'hexagon'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dictionary to Changes sides into shapes\n",
    "sides_to_names = {}\n",
    "sides_to_names[3] = 'traingle'\n",
    "sides_to_names[4] = 'square'\n",
    "sides_to_names[5] = 'pentagon'\n",
    "sides_to_names[6] = 'hexagon'\n",
    "sides_to_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c8ad73-43b2-414d-918c-17edcff7d336",
   "metadata": {},
   "source": [
    "<p style=\"font-size:15px;\">Dictionary for indexing by model</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0aa3728b-1349-4df2-a702-80ce3f24f1e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: 0, 4: 1, 5: 2, 6: 3}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dictionary to change sides into encoding values\n",
    "sides_to_encoding = {}\n",
    "sides_to_encoding[3] = 0\n",
    "sides_to_encoding[4] = 1\n",
    "sides_to_encoding[5] = 2\n",
    "sides_to_encoding[6] = 3\n",
    "sides_to_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28622c6c-563e-4389-b80a-b1a2c9128dd1",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px;\"><strong>Creating shapes and encoding data</strong></p>\n",
    "<p style=\"font-size:15px;\">Using dictionaries to turn # of sides into data for each row<br> <br> </p>\n",
    "\n",
    "\n",
    "\n",
    "<p style=\"font-size:20px;\"><strong>Easy to understand code</strong></p>\n",
    "<p style=\"color:gray;\"> shapes = [] <br>\n",
    "for i in range(3): <br>\n",
    "  shape_name = sides_to_names[data[i]]<br>\n",
    "  shapes.append(shape_name) </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7acbd037-8730-484e-ba9a-8b34b3e02210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                       filename  sides     shape  encoding\n",
       "0     70aaa621-1345-4541-a954-ee9856daaf18.png      4    square         1\n",
       "1     ea0d8d14-596a-4365-b007-6325fc96e0f4.png      3  traingle         0\n",
       "2     48c1fc5a-8b6b-4555-bb6a-a7d42a5cedc2.png      4    square         1\n",
       "3     ad721906-604c-4682-ae5d-15539ef1dbc7.png      3  traingle         0\n",
       "4     510dd5ea-fb92-432e-91cc-ed4654a03ebd.png      6   hexagon         3\n",
       "...                                        ...    ...       ...       ...\n",
       "9995  e921970a-e09d-4760-ab46-9a33f863d1ef.png      5  pentagon         2\n",
       "9996  bf398918-a475-42f1-adc0-59497120bcbd.png      3  traingle         0\n",
       "9997  c4065a6d-5339-46f5-9917-2831698d4fb8.png      6   hexagon         3\n",
       "9998  afd51b22-725a-4c43-8b40-dba5a83952c4.png      3  traingle         0\n",
       "9999  e07de190-c136-465b-b2a9-04944aa7980c.png      4    square         1\n",
       "\n",
       "[10000 rows x 4 columns]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Turns sides into Shapes\n",
    "shapes = [sides_to_names[sides] for sides in data]\n",
    "encoding = [sides_to_encoding[sides] for sides in data]\n",
    "\n",
    "'''\n",
    "shapes = []\n",
    "for i in range(3):\n",
    "  shape_name = sides_to_names[data[i]]\n",
    "  shapes.append(shape_name)\n",
    "\n",
    "'''\n",
    "\n",
    "df['shape'] = shapes\n",
    "df['encoding'] = encoding\n",
    "df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f183d86e-a475-42d4-a450-c73a58929fb8",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px;\"><strong>Creates data and lables</strong></p>\n",
    "<p style=\"font-size:15px;\">X is the question and y and is the answer<br>X is each a 128x128 image and y represents each polygon with an index</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22cecee9-7f15-49fc-9941-010485472bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['encoding']\n",
    "\n",
    "X = []\n",
    "for img_file_name in df['filename']:\n",
    "    img_path = \"archive/images/content/images/\" + img_file_name\n",
    "    img = load_img(img_path, target_size=(128, 128))  # target size\n",
    "    img_array = img_to_array(img)\n",
    "    img_array /= 255.0  # normalize pixel values to range [0, 1]\n",
    "    X.append(img_array)\n",
    "\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a61c38-c6f0-46fd-9afa-9d8f2cdf1ef6",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px;\"><strong>Splits data into train and test</strong></p>\n",
    "<p style=\"font-size:15px;\">Creates train, test, categorical, and validation varibles used to train and test the model</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac422df7-6cb3-4c8d-88f3-2e4fa4ea024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_validation, y_train_categorical, y_validation = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0622281-33c5-42eb-bc03-e1e0c20fcdaa",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px;\"><strong>Preventing Overtraining</strong></p>\n",
    "<p style=\"font-size:15px;\">Randomizing Pre-Model Data by randomly affecting attibtues of polygons<br>Randomizes rotation, width, height, zoom, and flip</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cb637b9-121c-4674-887c-4b2e781013d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shifts Data to prevent overtaining\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4973ff8e-5fee-4f1f-84d7-6d0b465241b6",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px;\"><strong>Creates Extra Variables</strong></p>\n",
    "<p style=\"font-size:15px;\">Used for modified model fitting to implement data radomization and epoch validation</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9fc9f36-d8ed-40c2-97cb-2120bd63c4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates Categorical Y data to implement data randomization\n",
    "y_train_categorical = keras.utils.to_categorical(y_train, 4)\n",
    "y_test_categorical = keras.utils.to_categorical(y_test, 4)\n",
    "\n",
    "#y_train_categorical = to_categorical(y_train_categorical, num_classes=4)\n",
    "y_validation = to_categorical(y_validation, num_classes=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0216476b-6d87-4384-ad65-4aa2e1940e76",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px;\"><strong>Early Stopping</strong></p>\n",
    "<p style=\"font-size:15px;\">Ends training early once validation accuracy stops improving</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45f581ec-79ae-4d2c-aa84-877085710047",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy', \n",
    "    patience=4,  \n",
    "    restore_best_weights=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14c4fe2-51d6-4c44-a3ac-a856699769ac",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px;\"><strong>Defining Model</strong></p>\n",
    "<p style=\"font-size:15px;\">Creates a two hidden layer CNN and compiling model using categorical crossentropy<br>\n",
    "The goal is to reduce crossentropy loss, using categorical crossentropy reduces loss for multi-class models</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4de6768a-7c42-4d3c-92c0-96d4c5f56f94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3afe3bd-ad16-4e3d-9282-7199290aa7fa",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px;\"><strong>Fitting Model</strong></p>\n",
    "<p style=\"font-size:15px;\">Fits model using randomized data (datagen) with a batch size of 32 and running 35 epochs</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1caab97b-0b59-43ea-ada1-7e3aeb83d034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 10:20:09.910476: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 41s 132ms/step - loss: 1.3876 - accuracy: 0.2641 - val_loss: 1.3814 - val_accuracy: 0.2540\n",
      "Epoch 2/35\n",
      "250/250 [==============================] - 32s 128ms/step - loss: 1.3795 - accuracy: 0.2799 - val_loss: 1.3496 - val_accuracy: 0.2840\n",
      "Epoch 3/35\n",
      "250/250 [==============================] - 32s 128ms/step - loss: 1.3556 - accuracy: 0.3038 - val_loss: 1.3018 - val_accuracy: 0.3165\n",
      "Epoch 4/35\n",
      "250/250 [==============================] - 32s 128ms/step - loss: 1.1565 - accuracy: 0.4469 - val_loss: 0.7396 - val_accuracy: 0.7005\n",
      "Epoch 5/35\n",
      "250/250 [==============================] - 32s 128ms/step - loss: 0.7019 - accuracy: 0.7065 - val_loss: 0.3571 - val_accuracy: 0.8450\n",
      "Epoch 6/35\n",
      "250/250 [==============================] - 32s 128ms/step - loss: 0.4278 - accuracy: 0.8303 - val_loss: 0.1617 - val_accuracy: 0.9400\n",
      "Epoch 7/35\n",
      "250/250 [==============================] - 32s 127ms/step - loss: 0.2924 - accuracy: 0.8917 - val_loss: 0.1231 - val_accuracy: 0.9505\n",
      "Epoch 8/35\n",
      "250/250 [==============================] - 32s 127ms/step - loss: 0.2425 - accuracy: 0.9076 - val_loss: 0.0822 - val_accuracy: 0.9720\n",
      "Epoch 9/35\n",
      "250/250 [==============================] - 32s 127ms/step - loss: 0.1802 - accuracy: 0.9334 - val_loss: 0.1003 - val_accuracy: 0.9585\n",
      "Epoch 10/35\n",
      "250/250 [==============================] - 32s 127ms/step - loss: 0.1559 - accuracy: 0.9408 - val_loss: 0.0649 - val_accuracy: 0.9755\n",
      "Epoch 11/35\n",
      "250/250 [==============================] - 32s 128ms/step - loss: 0.1538 - accuracy: 0.9396 - val_loss: 0.0390 - val_accuracy: 0.9920\n",
      "Epoch 12/35\n",
      "250/250 [==============================] - 32s 127ms/step - loss: 0.1326 - accuracy: 0.9489 - val_loss: 0.0504 - val_accuracy: 0.9855\n",
      "Epoch 13/35\n",
      "250/250 [==============================] - 32s 128ms/step - loss: 0.1298 - accuracy: 0.9534 - val_loss: 0.0404 - val_accuracy: 0.9860\n",
      "Epoch 14/35\n",
      "250/250 [==============================] - 32s 127ms/step - loss: 0.1140 - accuracy: 0.9576 - val_loss: 0.0256 - val_accuracy: 0.9925\n",
      "Epoch 15/35\n",
      "250/250 [==============================] - 32s 127ms/step - loss: 0.1145 - accuracy: 0.9581 - val_loss: 0.0326 - val_accuracy: 0.9885\n",
      "Epoch 16/35\n",
      "250/250 [==============================] - 32s 127ms/step - loss: 0.1030 - accuracy: 0.9621 - val_loss: 0.0271 - val_accuracy: 0.9910\n",
      "Epoch 17/35\n",
      "250/250 [==============================] - 32s 127ms/step - loss: 0.1036 - accuracy: 0.9634 - val_loss: 0.0243 - val_accuracy: 0.9915\n",
      "Epoch 18/35\n",
      "250/250 [==============================] - 32s 129ms/step - loss: 0.0871 - accuracy: 0.9659 - val_loss: 0.0255 - val_accuracy: 0.9905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14d6e0551e10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit Model\n",
    "#model.fit(datagen.flow(X_train, y_train_categorical, batch_size=32), steps_per_epoch=len(X_train) / 32, epochs=20)\n",
    "\n",
    "model.fit(datagen.flow(X_train, y_train_categorical, batch_size=32), \n",
    "          steps_per_epoch=len(X_train) / 32, \n",
    "          epochs=35, \n",
    "          validation_data=(X_validation, y_validation),\n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749957d7-c983-4264-99c0-300e4d671683",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px;\"><strong>Tests Model</strong></p>\n",
    "<p style=\"font-size:15px;\">Evaluates model loss and accuracy</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c25ddf2-e418-4af2-b094-7d2971ae1bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 20ms/step - loss: 0.0256 - accuracy: 0.9925\n",
      "Test Loss: 0.02561393938958645\n",
      "Test Accuracy: 0.9925000071525574\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test_categorical)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0453377-c8e6-411c-a14c-0d9ae5ee54cd",
   "metadata": {},
   "source": [
    "<p style=\"font-size:20px;background-color:SlateBlue;\"><strong>Things that didn't work</strong></p>\n",
    "<p style=\"font-size:15px;\">Using SGD and RMS optimizers instead of ADAM<br><br>SGD provdes a fixe system for updating parameters and requires heavy tuning of hyperparameters<br>RMS is an adaptive learning model which updating parameters depending on recent gradiants<br>Adam is even more adaptive, tuning for each parameter and requires less tuning of hyperparameters<br><br>The reason ADAM works the best is because it does not need heavy hyperparameter tuning, unlike SGD and RMS</p>\n",
    "<p style=\"font-size:18px;background-color:gray;\"><strong>Overfitting</strong></p>\n",
    "<p style=\"font-size:15px;\">Originally the model was overfitting the data because the four classes of polygons were all similar placed in the origin, and only having different rotations<br>This issue was fixed by adding radomization to the data by using datagen/ImageDataGenerator. This augments the data to help the models generalization.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1423069b-3488-4895-9a25-628706fb69df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (mlbd)",
   "language": "python",
   "name": "mlbd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
